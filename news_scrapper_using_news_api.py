# -*- coding: utf-8 -*-
"""News_Scrapper_using News API.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mao3B9xAuV1I8wOxFZh-VHGvLo3WAFNY
"""

import requests

news_api_key = "8e94d1c99acf413b90d8b7e32137c0ec"

url_1 = ('https://newsapi.org/v2/everything?'
       'q=Apple&'
       'from=2023-02-19&'
       'sortBy=popularity&'
       'apiKey={news_api_key}')
url_7=f"https://newsapi.org/v2/top-headlines?country=us&apiKey={news_api_key}"
url_2=f"https://newsapi.org/v2/top-headlines?sources=bbc-news&apiKey={news_api_key}"
url_3=f"https://newsapi.org/v2/everything?q=bitcoin&apiKey={news_api_key}"
main_page = requests.get(url_2).json()
#article= main_page["articles"]
head=[]

article= main_page["articles"]
for ar in article:
  head.append(ar["description"])
for i in range(10):
  print(f"{i+1}. {head[i]}\n")

main_page = requests.get(url_7).json()
#article= main_page["articles"]
head=[]
article= main_page["articles"]
for ar in article:
  head.append(ar["description"])
for i in range(10):
  print(f"{i+1}. {head[i]}\n")

main_page = requests.get(url_3).json()
#article= main_page["articles"]
head=[]
article= main_page["articles"]
for ar in article:
  head.append(ar["description"])
for i in range(10):
  print(f"{i+1}. {head[i]}\n")

url_1="https://newsapi.org/v2/top-headlines?country=ind&apiKey={news_api_key}"

main_page = requests.get(url_2).json()
article= main_page["articles"]
head=[]
for ar in article:
  head.append(ar["description"])
for i in range(6):
  print(f"{i+1}{head[i]}\n")



import requests

url = ('https://newsapi.org/v2/everything?'
       'q=Current Affairs&'
       'from=2023-02-19&'
       'sortBy=popularity&'
       'apiKey=8e94d1c99acf413b90d8b7e32137c0ec')

response = requests.get(url)

print(response.json())

main_page = requests.get(url).json()
article= main_page["articles"]
head=[]
for ar in article:
  head.append(ar["description"])
for i in range(25):
  print(f"{i+1}{head[i]}\n")